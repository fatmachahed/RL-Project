# Agent0 — baseline (K=1, n=1, déterministe)
name: "Agent0"
env_name: "CartPole-v1"
K: 1
n_steps: 1
stochastic_rewards: false
lr_actor: 0.00001
lr_critic: 0.001
gamma: 0.99
max_steps: 500000
entropy_coef: 0.01
eval_freq: 20000



# Agent1 - (K=1, n=1, stochastique 90% masking)
name: "Agent1"
env_name: "CartPole-v1"
K: 1
n_steps: 1
stochastic_rewards: true
lr_actor: 0.00001  # 10x plus élevé que Agent0
lr_critic: 0.001
gamma: 0.99
max_steps: 500000
entropy_coef: 0.01
eval_freq: 20000




# Agent2 - (K=6, n=1, stochastique)
name: "Agent2"
env_name: "CartPole-v1"
K: 6
n_steps: 1
stochastic_rewards: true
lr_actor: 0.00001  # ← 30x plus élevé (K=6 réduit variance)
lr_critic: 0.001 # augmenté 
gamma: 0.99
max_steps: 500000
entropy_coef: 0.01
eval_freq: 20000




# Agent3 - (K=1, n=6, stochastique)
name: "Agent3"
env_name: "CartPole-v1"
K: 1
n_steps: 6
stochastic_rewards: true
lr_actor: 0.00001  # ← 20x plus élevé (n=6 réduit variance)
lr_critic: 0.001
gamma: 0.99
max_steps: 500000
entropy_coef: 0.01
eval_freq: 20000



# Agent4 - (K=6, n=6, stochastique) - LE MEILLEUR 
name: "Agent4"
env_name: "CartPole-v1"
K: 6
n_steps: 6
stochastic_rewards: true
lr_actor: 0.0003  # ← 50x plus élevé ! (K=6 + n=6 = très stable)
lr_critic: 0.003  # ← Aussi augmenté fortement
gamma: 0.99
max_steps: 500000
entropy_coef: 0.01
eval_freq: 20000




